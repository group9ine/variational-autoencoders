{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb34c7a8",
   "metadata": {},
   "source": [
    "# Convolutional 2D VAE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2121bf15",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import linalg as la\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Input,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    Reshape,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d142e12f",
   "metadata": {},
   "source": [
    "## Data Input and Pre Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "728ed42a",
   "metadata": {},
   "source": [
    "Define core features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "numpart = 30\n",
    "latent_dim = 50\n",
    "box_size = 10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4ec27dc",
   "metadata": {},
   "source": [
    "Import and reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20664e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r\"\\\\wsl$\\Ubuntu\\home\\alepitte\\ale\\uni\\variational-autoencoders\\mc-sampling\\dump\\test_30_10_1_0.75_0.2_10000_2500_5_x.txt\"\n",
    "# fname = '/Users/lorenzobarbiero/Documents/GitHub/variational-autoencoders/mc-sampling/good-runs/test_30_10_1_0.75_0.2_10000_2500_5_x.txt'\n",
    "\n",
    "with open(fname) as f:\n",
    "    df0 = pd.DataFrame(\n",
    "        [\n",
    "            [float(i.strip()) for i in s.split(\" \") if i != \"\"]\n",
    "            for s in f.read().split(\"\\n\")\n",
    "            if s != \"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "fname1 = r\"\\\\wsl$\\Ubuntu\\home\\alepitte\\ale\\uni\\variational-autoencoders\\mc-sampling\\dump\\test_30_10_0.1_0.75_0.2_10000_2500_0_x.txt\"\n",
    "\n",
    "with open(fname1) as f:\n",
    "    df1 = pd.DataFrame(\n",
    "        [\n",
    "            [float(i.strip()) for i in s.split(\" \") if i != \"\"]\n",
    "            for s in f.read().split(\"\\n\")\n",
    "            if s != \"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "data = pd.concat([df0, df1])\n",
    "\n",
    "labels = np.array([0] * len(df0) + [1] * len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be071e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcs = np.array(data).reshape((-1, numpart, dim)) / (\n",
    "    box_size * np.sqrt(dim)\n",
    ")\n",
    "print(vcs.shape, vcs[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77802d2f",
   "metadata": {},
   "source": [
    "Sort by distance from origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ce942",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortmode = 1\n",
    "if sortmode == 1:\n",
    "    # Calculate distances from (0, 0)\n",
    "    distances = np.sqrt(vcs[:, :, 0] ** 2 + vcs[:, :, 1] ** 2)\n",
    "    idx = np.argsort(distances, axis=1)\n",
    "    sorted_vcs = np.empty_like(vcs)\n",
    "    for i in range(len(vcs)):\n",
    "        sorted_vcs[i] = vcs[i][idx[i]]\n",
    "\n",
    "    print(sorted_vcs.shape, \"\\n\", sorted_vcs[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecc829a1",
   "metadata": {},
   "source": [
    "### Compute distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d724534",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = np.zeros((len(vcs), numpart, numpart))\n",
    "\n",
    "for i in range(len(vcs)):\n",
    "    dm[i] = squareform(\n",
    "        pdist(sorted_vcs[i], metric=\"euclidean\"), force=\"no\", checks=True\n",
    "    )\n",
    "\n",
    "print(dm.shape, \"\\n\", dm[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc556d3b",
   "metadata": {},
   "source": [
    "Split in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8163850",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 0.8\n",
    "\n",
    "m = sorted_vcs.shape[0]\n",
    "print(m)\n",
    "permutation = np.random.permutation(m)  # random permurtation\n",
    "\n",
    "sorted_vcs = sorted_vcs[permutation]\n",
    "labels = labels[permutation]\n",
    "dm = dm[permutation]\n",
    "\n",
    "# m_training needs to be the number of samples in the training set\n",
    "m_training = int(m * train_perc)\n",
    "\n",
    "# m_test needs to be the number of samples in the test set\n",
    "m_test = m - m_training\n",
    "\n",
    "trainset_conf = sorted_vcs[:m_training]\n",
    "testset_conf = sorted_vcs[m_training:]\n",
    "\n",
    "trainset_mat = dm[:m_training]\n",
    "testset_mat = dm[m_training:]\n",
    "\n",
    "\n",
    "# check if there are at least 10 elements from class -1 and 1\n",
    "c1 = np.count_nonzero(labels[:m_training] == 1)\n",
    "c0 = np.count_nonzero(labels[:m_training] == 0)\n",
    "\n",
    "print(\n",
    "    \"number of 1 in training set:\",\n",
    "    c1,\n",
    "    \"\\n\",\n",
    "    \"number of 0 in training set:\",\n",
    "    c0,\n",
    ")\n",
    "\n",
    "while c1 < 1000 or c0 < 1000:  # permute until the condition is reached\n",
    "    permutation = np.random.permutation(m)  # random permurtation\n",
    "\n",
    "    sorted_vcs = sorted_vcs[permutation]\n",
    "    labels = labels[permutation]\n",
    "    dm = dm[permutation]\n",
    "\n",
    "    trainset_conf = sorted_vcs[:m_training]\n",
    "    testset_conf = sorted_vcs[m_training:]\n",
    "\n",
    "    trainset_mat = dm[:m_training]\n",
    "    testset_mat = dm[m_training:]\n",
    "\n",
    "    c1 = np.count_nonzero(labels[:m_training] == 1)\n",
    "    c0 = np.count_nonzero(labels[:m_training] == 0)\n",
    "\n",
    "\n",
    "print(\"Shape of training set: \" + str(trainset_conf.shape))\n",
    "print(\"Shape of test set: \" + str(testset_mat.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ace60bc",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder (Model 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a611a5b",
   "metadata": {},
   "source": [
    "### Sampling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f699c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e55e13e",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67faee0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(numpart, numpart, 1))\n",
    "x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
    "# x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "conv_shape = K.int_shape(x)  # Shape of conv to be provided to decoder\n",
    "x = Flatten()(x)  # Flatten\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(\n",
    "    encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\"\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcc3e390",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0907c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "x = Dense(\n",
    "    conv_shape[1] * conv_shape[2] * conv_shape[3], activation=\"relu\"\n",
    ")(decoder_input)\n",
    "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "x = Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "# x = Conv2DTranspose(128, 3, padding='same', activation='relu')(x)\n",
    "x = Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "decoder_outputs = Conv2DTranspose(\n",
    "    1, 3, padding=\"same\", activation=\"sigmoid\", name=\"decoder_output\"\n",
    ")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a3299e2",
   "metadata": {},
   "source": [
    "### VAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            size = reconstruction.shape[\n",
    "                1:\n",
    "            ]  # Extract dimensions excluding the first 'None' dimension\n",
    "            noise = np.random.normal(0, 0.1, size=size)\n",
    "            reconstruction = reconstruction + noise\n",
    "\n",
    "            # Reshape data to match decoder output shape\n",
    "            data = tf.expand_dims(data, axis=-1)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(data, reconstruction)\n",
    "            )\n",
    "            kl_loss = -0.5 * (\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            )\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + reg_lambda * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77af32ab",
   "metadata": {},
   "source": [
    "### Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85776b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg_lambda = 0.001\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")  # lower learning rate\n",
    "fit = vae.fit(trainset_mat, epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "fig, AX = plt.subplots(1, 2, figsize=(14, 6.0))\n",
    "ax = AX[0]\n",
    "ax.plot(fit.history[\"loss\"], label=\"MSE loss\", c=\"b\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"MSE loss\")\n",
    "ax.legend()\n",
    "ax = AX[1]\n",
    "ax.plot(fit.history[\"kl_loss\"], label=\"KL loss\", c=\"r\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"KL loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e0e846",
   "metadata": {},
   "source": [
    "## Evaluate performance\n",
    "We'll now use the test set to explore the latent space distribution of data and the reconstruction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = np.array(vae.encoder.predict(testset_mat))\n",
    "encoded_train = np.array(vae.encoder.predict(trainset_mat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae37675",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fb5ff61",
   "metadata": {},
   "source": [
    "z_mean are the first dimension, z_log_var the second (used in training), we're interested in the third dimension, which are the sampled z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = encoded_test[2, :, :]\n",
    "print(dim1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "357c9a7c",
   "metadata": {},
   "source": [
    "Sampling in the latent space is reasonably gaussian as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(dim1, columns=[\"x\", \"y\"])\n",
    "# sns.jointplot(x=\"x\", y=\"y\", data=df);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5298c76a",
   "metadata": {},
   "source": [
    "We can now use the data to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40394aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test = np.array(decoder.predict(encoded_test[2, :, :])).reshape(\n",
    "    -1, numpart, numpart\n",
    ")\n",
    "decoded_train = np.array(decoder.predict(encoded_train[2, :, :])).reshape(\n",
    "    -1, numpart, numpart\n",
    ")\n",
    "print(decoded_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7602682f",
   "metadata": {},
   "source": [
    "### Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 20\n",
    "df = pd.DataFrame(decoded_test[ind])\n",
    "sns.heatmap(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(testset_mat[ind])\n",
    "sns.heatmap(data=df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2693cb63",
   "metadata": {},
   "source": [
    "## Coordinates Reconstructor (Model 2)\n",
    "The reconstructor is trained on the original distance matrices and predicts the decoded matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inputs = layers.Input(shape=(numpart, numpart))\n",
    "x = Flatten()(rec_inputs)\n",
    "x = layers.Dense(int(numpart**2 * 4 / 5), activation=\"relu\")(x)\n",
    "x = layers.Dense(int(numpart**2 * 3 / 5), activation=\"relu\")(x)\n",
    "x = layers.Dense(int(numpart**2 * 2 / 5), activation=\"relu\")(x)\n",
    "x = layers.Dense(int(numpart**2 * 1 / 5), activation=\"relu\")(x)\n",
    "x = layers.Dense(int(numpart * dim))(x)\n",
    "rec_outputs = Reshape((numpart, dim))(x)\n",
    "reconstruction = keras.Model(rec_inputs, rec_outputs)\n",
    "reconstruction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef36ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstruction.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    ")  # lower learning rate\n",
    "fit = reconstruction.fit(\n",
    "    trainset_mat, trainset_conf, epochs=30, batch_size=128, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_test = np.array(reconstruction.predict(testset_mat))\n",
    "rec_test_dec = np.array(reconstruction.predict(decoded_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca075e92",
   "metadata": {},
   "source": [
    "### Evaluate performance\n",
    "Original data is in blue, reconstructed original configurations in gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 20\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot()\n",
    "l = np.sqrt(2)\n",
    "ax.scatter(\n",
    "    rec_test[ind, :, 0] * l, rec_test[ind, :, 1] * l, s=30, c=\"gold\"\n",
    ")\n",
    "ax.scatter(\n",
    "    testset_conf[ind, :, 0] * l,\n",
    "    testset_conf[ind, :, 1] * l,\n",
    "    s=30,\n",
    "    c=\"#023e8a\",\n",
    ")\n",
    "ax.set_xlim(-0.15, 1.15)\n",
    "ax.set_ylim(-0.15, 1.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cba87eac",
   "metadata": {},
   "source": [
    "Original data is in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 20\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot()\n",
    "l = np.sqrt(2)\n",
    "ax.scatter(\n",
    "    rec_test_dec[ind, :, 0] * l,\n",
    "    rec_test_dec[ind, :, 1] * l,\n",
    "    s=30,\n",
    "    c=\"#e63946\",\n",
    ")\n",
    "ax.scatter(\n",
    "    testset_conf[ind, :, 0] * l,\n",
    "    testset_conf[ind, :, 1] * l,\n",
    "    s=30,\n",
    "    c=\"#023e8a\",\n",
    ")\n",
    "ax.set_xlim(-0.15, 1.15)\n",
    "ax.set_ylim(-0.15, 1.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ed391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Create the figure and axis objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "nframes = 100\n",
    "\n",
    "\n",
    "# Define the animation function\n",
    "def update(ind):\n",
    "    ax.clear()\n",
    "    plt.scatter(\n",
    "        rec_test[ind, :, 0] * l, rec_test[ind, :, 1] * l, s=20, c=\"b\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        testset_conf[ind, :, 0] * l,\n",
    "        testset_conf[ind, :, 1] * l,\n",
    "        s=20,\n",
    "        c=\"y\",\n",
    "    )\n",
    "    ax.set_title(f\"Scatter plot ({ind}/{nframes})\")\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "animation = FuncAnimation(fig, update, frames=nframes, interval=400)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "animation.save(\"conv2dist.gif\", writer=\"imagemagick\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0642e57",
   "metadata": {},
   "source": [
    "## Deez Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0497eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def label_vis(vae, data, labels):\n",
    "    # prediction\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    transformed_data = pca.fit_transform(z_mean)\n",
    "    variance_ratio = pca.explained_variance_ratio_\n",
    "    print(variance_ratio)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(transformed_data[:, 0], transformed_data[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36969448",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vis(vae, dm, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf507cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
