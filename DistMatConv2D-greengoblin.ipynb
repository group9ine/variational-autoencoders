{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb34c7a8",
      "metadata": {
        "id": "cb34c7a8"
      },
      "source": [
        "# Convolutional 2D VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aMHw7UEOnjH",
      "metadata": {
        "id": "6aMHw7UEOnjH"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive/\")\n",
        "\n",
        "# %cd drive/MyDrive/Colab\\ Notebooks/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2121bf15",
      "metadata": {
        "id": "2121bf15"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f7cdff",
      "metadata": {
        "id": "79f7cdff"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import linalg as la\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.layers import (\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    Input,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Lambda,\n",
        "    Reshape,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d142e12f",
      "metadata": {
        "id": "d142e12f"
      },
      "source": [
        "## Data Input and Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728ed42a",
      "metadata": {
        "id": "728ed42a"
      },
      "source": [
        "Define core features of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04bdb140",
      "metadata": {
        "id": "04bdb140"
      },
      "outputs": [],
      "source": [
        "dim = 2\n",
        "numpart = 30\n",
        "latent_dim = 40\n",
        "box_size = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ec27dc",
      "metadata": {
        "id": "a4ec27dc"
      },
      "source": [
        "Import and reshape data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = np.asarray(glob(\"gamma*_100000_*_x.txt\"), dtype=\"str\")\n",
        "test_files = np.asarray(glob(\"gamma*_10000_*_x.txt\"), dtype=\"str\")\n",
        "\n",
        "if train_files.size != test_files.size:\n",
        "    print(\"Missing files!\")\n",
        "\n",
        "gamma = np.sort([f.split(\"_\")[1] for f in train_files]).astype(float)\n",
        "num_gammas = train_files.size\n",
        "\n",
        "for files in train_files, test_files:\n",
        "    files = files[np.argsort([f.split(\"_\")[1] for f in files])]\n",
        "\n",
        "train_arrays = [np.loadtxt(f) for f in train_files]\n",
        "train_data = np.vstack(train_arrays)\n",
        "train_data = train_data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
        "train_labels = np.hstack([[i] * len(a) for i, a in enumerate(train_arrays)])\n",
        "\n",
        "test_arrays = [np.loadtxt(f) for f in test_files]\n",
        "test_data = np.vstack(test_arrays)\n",
        "test_data = test_data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
        "test_labels = np.hstack([[i] * len(a) for i, a in enumerate(test_arrays)])\n",
        "\n",
        "print(f\"Training data: {train_data.shape}\\nTest data: {test_data.shape}\")"
      ],
      "metadata": {
        "id": "DU6g9tF0JLT7",
        "outputId": "a4bf2b6c-569c-47d2-f8a9-e7ede25bcad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DU6g9tF0JLT7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: (400000, 30, 2)\n",
            "Test data: (40000, 30, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77802d2f",
      "metadata": {
        "id": "77802d2f"
      },
      "source": [
        "Sort by distance from origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935ce942",
      "metadata": {
        "id": "935ce942"
      },
      "outputs": [],
      "source": [
        "sort_idx = np.argsort(train_data[:, :, 0]**2 + train_data[:, :, 1]**2)\n",
        "train_data = np.array(\n",
        "    [sample[sort_idx[i]] for i, sample in enumerate(train_data)]\n",
        ")\n",
        "\n",
        "sort_idx = np.argsort(test_data[:, :, 0]**2 + test_data[:, :, 1]**2)\n",
        "test_data = np.array(\n",
        "    [sample[sort_idx[i]] for i, sample in enumerate(test_data)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc829a1",
      "metadata": {
        "id": "ecc829a1"
      },
      "source": [
        "### Compute distance matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d724534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d724534",
        "outputId": "88fc8937-0af3-47e9-9124-bd85e0279674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training distance matrix shape: (400000, 30, 30)\n",
            "Test distance matrix shape: (40000, 30, 30)\n"
          ]
        }
      ],
      "source": [
        "# metric=\"euclidean\", force=\"no\", checks=True are by default\n",
        "train_dm = np.array([squareform(pdist(sample)) for sample in train_data])\n",
        "test_dm = np.array([squareform(pdist(sample)) for sample in test_data])\n",
        "\n",
        "print(f\"Training distance matrix shape: {train_dm.shape}\")\n",
        "print(f\"Test distance matrix shape: {test_dm.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e97d525",
      "metadata": {
        "id": "7e97d525"
      },
      "outputs": [],
      "source": [
        "m_train = train_data.shape[0]\n",
        "m_test = test_data.shape[0]\n",
        "\n",
        "train_perm = np.random.permutation(m_train)\n",
        "test_perm = np.random.permutation(m_test)\n",
        "\n",
        "train_data = train_data[train_perm]\n",
        "train_dm = train_dm[train_perm]\n",
        "train_labels = train_labels[train_perm]\n",
        "\n",
        "test_data = test_data[test_perm]\n",
        "test_dm = test_dm[test_perm]\n",
        "test_labels = test_labels[test_perm]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ace60bc",
      "metadata": {
        "id": "6ace60bc"
      },
      "source": [
        "## Variational Auto Encoder (Model 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a611a5b",
      "metadata": {
        "id": "5a611a5b"
      },
      "source": [
        "### Sampling class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f699c38",
      "metadata": {
        "id": "1f699c38"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e55e13e",
      "metadata": {
        "id": "0e55e13e"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67faee0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67faee0e",
        "outputId": "5f5b9ba2-36d6-4408-cbdc-050dc13c4f9f",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30, 30, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 30, 30, 60)   600         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 30, 30, 50)   27050       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 45000)        0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 40)           1800040     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 40)           1800040     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 40)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,627,730\n",
            "Trainable params: 3,627,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs = keras.Input(shape=(numpart, numpart, 1))\n",
        "x = Conv2D(60, 3, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
        "x = Conv2D(50, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "conv_shape = K.int_shape(x)  # Shape of conv to be provided to decoder\n",
        "x = Flatten()(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(\n",
        "    encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\"\n",
        ")\n",
        "encoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc3e390",
      "metadata": {
        "id": "fcc3e390"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0907c43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0907c43",
        "outputId": "42339aa4-02e9-4952-e84d-e45d6650373d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 40)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 45000)             1845000   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 30, 30, 50)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 30, 30, 50)       22550     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 30, 30, 60)       27060     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " decoder_output (Conv2DTrans  (None, 30, 30, 1)        541       \n",
            " pose)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,895,151\n",
            "Trainable params: 1,895,151\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "x = Dense(\n",
        "    conv_shape[1] * conv_shape[2] * conv_shape[3], activation=\"relu\"\n",
        ")(decoder_input)\n",
        "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "x = Conv2DTranspose(50, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = Conv2DTranspose(60, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "decoder_outputs = Conv2DTranspose(\n",
        "    1, 3, padding=\"same\", activation=\"sigmoid\", name=\"decoder_output\"\n",
        ")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a3299e2",
      "metadata": {
        "id": "8a3299e2"
      },
      "source": [
        "### VAE Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5816189c",
      "metadata": {
        "id": "5816189c"
      },
      "outputs": [],
      "source": [
        "reg_lambda = 0.00035\n",
        "\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            # Extract dimensions excluding the first 'None' dimension\n",
        "            size = reconstruction.shape[1:]\n",
        "            # noise = np.random.normal(0, 0.1, size=size)\n",
        "            # reconstruction = reconstruction + noise\n",
        "\n",
        "            # Reshape data to match decoder output shape\n",
        "            data = tf.expand_dims(data, axis=-1)\n",
        "\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                keras.losses.mean_squared_error(data, reconstruction)\n",
        "            )\n",
        "            kl_loss = -0.5 * (\n",
        "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            )\n",
        "            kl_loss = tf.reduce_mean(kl_loss)\n",
        "            total_loss = reconstruction_loss + reg_lambda * kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77af32ab",
      "metadata": {
        "id": "77af32ab"
      },
      "source": [
        "### Train VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f85776b",
      "metadata": {
        "id": "1f85776b",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e8e02a-9002-4988-a286-1144452ef76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3125/3125 - 81s - loss: 0.0036 - reconstruction_loss: 0.0030 - kl_loss: 1.8186 - 81s/epoch - 26ms/step\n",
            "Epoch 2/100\n",
            "3125/3125 - 70s - loss: 0.0020 - reconstruction_loss: 0.0012 - kl_loss: 2.0394 - 70s/epoch - 22ms/step\n",
            "Epoch 3/100\n",
            "3125/3125 - 70s - loss: 0.0018 - reconstruction_loss: 0.0011 - kl_loss: 2.0246 - 70s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "3125/3125 - 71s - loss: 0.0017 - reconstruction_loss: 0.0010 - kl_loss: 2.0137 - 71s/epoch - 23ms/step\n",
            "Epoch 5/100\n",
            "3125/3125 - 72s - loss: 0.0016 - reconstruction_loss: 9.4657e-04 - kl_loss: 2.0053 - 72s/epoch - 23ms/step\n",
            "Epoch 6/100\n",
            "3125/3125 - 72s - loss: 0.0016 - reconstruction_loss: 9.0504e-04 - kl_loss: 1.9999 - 72s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "3125/3125 - 72s - loss: 0.0016 - reconstruction_loss: 8.7281e-04 - kl_loss: 1.9942 - 72s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "3125/3125 - 72s - loss: 0.0015 - reconstruction_loss: 8.4728e-04 - kl_loss: 1.9915 - 72s/epoch - 23ms/step\n",
            "Epoch 9/100\n"
          ]
        }
      ],
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        ")  # lower learning rate\n",
        "fit = vae.fit(train_dm, epochs=100, batch_size=128, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa509d5",
      "metadata": {
        "id": "4fa509d5"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"font.size\"] = 12\n",
        "fig, AX = plt.subplots(1, 2, figsize=(14, 6.0))\n",
        "ax = AX[0]\n",
        "ax.plot(fit.history[\"loss\"], label=\"MSE loss\", c=\"b\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"MSE loss\")\n",
        "ax.legend()\n",
        "ax = AX[1]\n",
        "ax.plot(fit.history[\"kl_loss\"], label=\"KL loss\", c=\"r\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"KL loss\")\n",
        "ax.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1I1XvC5ranF1",
      "metadata": {
        "id": "1I1XvC5ranF1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "%rm -rf saved_model\n",
        "%mkdir -p saved_model\n",
        "tf.keras.models.save_model(vae.encoder, \"saved_model/encoder\")\n",
        "tf.keras.models.save_model(vae.decoder, \"saved_model/decoder\")\n",
        "!zip -r encoder.zip saved_model/encoder\n",
        "!zip -r decoder.zip saved_model/decoder\n",
        "\n",
        "files.download(\"encoder.zip\")\n",
        "files.download(\"decoder.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e0e846",
      "metadata": {
        "id": "a1e0e846"
      },
      "source": [
        "## Evaluate performance\n",
        "We'll now use the test set to explore the latent space distribution of data and the reconstruction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10df409c",
      "metadata": {
        "id": "10df409c"
      },
      "outputs": [],
      "source": [
        "encoded_test = np.array(vae.encoder.predict(test_dm))\n",
        "encoded_train = np.array(vae.encoder.predict(train_dm))\n",
        "\n",
        "print(encoded_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5298c76a",
      "metadata": {
        "id": "5298c76a"
      },
      "source": [
        "We can now use the data to decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40394aeb",
      "metadata": {
        "id": "40394aeb"
      },
      "outputs": [],
      "source": [
        "decoded_test = np.array(decoder.predict(encoded_test[2, :, :])).reshape(\n",
        "    -1, numpart, numpart\n",
        ")\n",
        "decoded_train = np.array(decoder.predict(encoded_train[2, :, :])).reshape(\n",
        "    -1, numpart, numpart\n",
        ")\n",
        "print(decoded_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7602682f",
      "metadata": {
        "id": "7602682f"
      },
      "source": [
        "### Check reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b1aad7",
      "metadata": {
        "id": "43b1aad7"
      },
      "outputs": [],
      "source": [
        "ind = 42\n",
        "df = pd.DataFrame(decoded_test[ind])\n",
        "sns.heatmap(data=df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f83de44",
      "metadata": {
        "id": "9f83de44"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(test_dm[ind])\n",
        "sns.heatmap(data=df2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jmSuP8bA0-gj",
      "metadata": {
        "id": "jmSuP8bA0-gj"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(abs(test_dm[ind] - decoded_test[ind]))\n",
        "sns.heatmap(data=df3, cmap=\"mako\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q5K9miXMuJBe",
      "metadata": {
        "id": "Q5K9miXMuJBe"
      },
      "source": [
        "## Alternative coordinates reconstructor\n",
        "Another way to achieve coordinates from the distance matrix is through a more analytical method that does not involve Machine Learning\n",
        "\n",
        "Step 1: retrieve coordinates from distance matrix (shifted and rotated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_ZPRS-4uj4l",
      "metadata": {
        "id": "b_ZPRS-4uj4l"
      },
      "outputs": [],
      "source": [
        "def gram_to_coordinates(distance_matrix):\n",
        "    # Get the number of points\n",
        "    n = distance_matrix.shape[0]\n",
        "\n",
        "    # Compute the Gram matrix\n",
        "    gram_matrix = -0.5 * (distance_matrix**2)\n",
        "\n",
        "    # Center the Gram matrix\n",
        "    gram_matrix_centered = (\n",
        "        gram_matrix\n",
        "        - np.mean(gram_matrix, axis=0)\n",
        "        - np.mean(gram_matrix, axis=1)[:, np.newaxis]\n",
        "        + np.mean(gram_matrix)\n",
        "    )\n",
        "\n",
        "    # Perform eigendecomposition of the centered Gram matrix\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(gram_matrix_centered)\n",
        "\n",
        "    # Sort eigenvalues and eigenvectors in descending order\n",
        "    indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvalues = eigenvalues[indices]\n",
        "    eigenvectors = eigenvectors[:, indices]\n",
        "\n",
        "    # Extract the positive square root of eigenvalues\n",
        "    sqrt_eigenvalues = np.sqrt(np.maximum(eigenvalues, 0))\n",
        "\n",
        "    # Compute the coordinates of the points in 2D space\n",
        "    coordinates = eigenvectors[:, :2] * sqrt_eigenvalues[:2]\n",
        "\n",
        "    return coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_1d1jY-lvCuz",
      "metadata": {
        "id": "_1d1jY-lvCuz"
      },
      "outputs": [],
      "source": [
        "coordinates = gram_to_coordinates(decoded_train[1])\n",
        "print(\"Coordinates of points:\")\n",
        "print(coordinates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E1klGEDQvXFJ",
      "metadata": {
        "id": "E1klGEDQvXFJ"
      },
      "outputs": [],
      "source": [
        "ind = 1\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot()\n",
        "l = np.sqrt(2)\n",
        "ax.scatter(\n",
        "    coordinates[:, 0] * l,\n",
        "    coordinates[:, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#e63946\",\n",
        ")\n",
        "ax.scatter(\n",
        "    test_data[ind, :, 0] * l,\n",
        "    test_data[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#023e8a\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTEXmtIhvbOP",
      "metadata": {
        "id": "sTEXmtIhvbOP"
      },
      "outputs": [],
      "source": [
        "def align_points(points1, points2):\n",
        "    # Center the points by subtracting their means\n",
        "    centered_points1 = points1 - np.mean(points1, axis=0)\n",
        "    centered_points2 = points2 - np.mean(points2, axis=0)\n",
        "\n",
        "    # Compute the covariance matrix\n",
        "    covariance_matrix = centered_points2.T @ centered_points1\n",
        "\n",
        "    # Perform singular value decomposition (SVD)\n",
        "    U, _, Vt = np.linalg.svd(covariance_matrix)\n",
        "\n",
        "    # Calculate the optimal rotation matrix\n",
        "    rotation_matrix = Vt.T @ U.T\n",
        "\n",
        "    # Calculate the optimal translation vector\n",
        "    translation_vector = np.mean(points2, axis=0) - np.mean(\n",
        "        points1 @ rotation_matrix, axis=0\n",
        "    )\n",
        "\n",
        "    # Transform points1 using the estimated rotation and translation\n",
        "    transformed_points = points1 @ rotation_matrix + translation_vector\n",
        "\n",
        "    return transformed_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wnG0-W04vd8J",
      "metadata": {
        "id": "wnG0-W04vd8J"
      },
      "outputs": [],
      "source": [
        "coordinates = align_points(coordinates, train_data[1])\n",
        "ind = 1\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot()\n",
        "l = np.sqrt(2)\n",
        "ax.scatter(\n",
        "    coordinates[:, 0] * l,\n",
        "    coordinates[:, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#e63946\",\n",
        ")\n",
        "ax.scatter(\n",
        "    train_data[ind, :, 0] * l,\n",
        "    train_data[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#023e8a\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "avhNsf23viFu",
      "metadata": {
        "id": "avhNsf23viFu"
      },
      "outputs": [],
      "source": [
        "rec_test_dec = np.zeros((test_data.shape))\n",
        "\n",
        "for i in range(0, len(rec_test_dec)):\n",
        "    rec_test_dec[i] = align_points(\n",
        "        gram_to_coordinates(decoded_test[i]), test_data[i]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LHOgCMzVvm53",
      "metadata": {
        "id": "LHOgCMzVvm53"
      },
      "outputs": [],
      "source": [
        "ind = 70\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot()\n",
        "l = np.sqrt(2)\n",
        "ax.scatter(\n",
        "    rec_test_dec[ind, :, 0] * l,\n",
        "    rec_test_dec[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#e63946\",\n",
        ")\n",
        "ax.scatter(\n",
        "    test_data[ind, :, 0] * l,\n",
        "    test_data[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#023e8a\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0642e57",
      "metadata": {
        "id": "b0642e57"
      },
      "source": [
        "## Deez Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0497eb4",
      "metadata": {
        "id": "a0497eb4"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def label_vis(vae, data, labels):\n",
        "    # prediction\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    transformed_data = pca.fit_transform(z_mean)\n",
        "    variance_ratio = pca.explained_variance_ratio_\n",
        "    print(variance_ratio)\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(transformed_data[:, 0], transformed_data[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36969448",
      "metadata": {
        "id": "36969448"
      },
      "outputs": [],
      "source": [
        "label_vis(vae, train_data, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LGQUmrnEnUJv",
      "metadata": {
        "id": "LGQUmrnEnUJv"
      },
      "source": [
        "## Energy test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf507cc6",
      "metadata": {
        "id": "bf507cc6"
      },
      "outputs": [],
      "source": [
        "def potential(x, gamma):\n",
        "    \"\"\"\n",
        "    Calculate LJ + gravitational potential given a positions array.\n",
        "\n",
        "    INPUTS\n",
        "        x: array of shape (num_particles, dimension)\n",
        "        gamma\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(x)\n",
        "    pot = 0.0\n",
        "    for i in range(n - 1):\n",
        "        pot += gamma * x[i, -1]\n",
        "        for j in range(i + 1, n):\n",
        "            r2 = np.sum((x[i, :] - x[j, :]) ** 2)\n",
        "            if r2 < 1.0:\n",
        "                continue\n",
        "            if r2 < 9.0:  # r_cut = 3 sigma\n",
        "                sr6 = 1.0 / r2**3\n",
        "                pot += 4 * (sr6**2 - sr6)\n",
        "    pot += gamma * x[-1, -1]\n",
        "\n",
        "    return pot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jCWq5na9_h9E",
      "metadata": {
        "id": "jCWq5na9_h9E"
      },
      "outputs": [],
      "source": [
        "scale_factor = box_size * np.sqrt(dim)\n",
        "ori_pots = [\n",
        "    potential(sample, gamma[test_labels[idx]])\n",
        "    for idx, sample in enumerate(testset_conf * scale_factor)\n",
        "]\n",
        "rec_pots = [\n",
        "    potential(sample, gamma[test_labels[idx]])\n",
        "    for idx, sample in enumerate(rec_test_dec * scale_factor)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aBWaQ0iX_qTw",
      "metadata": {
        "id": "aBWaQ0iX_qTw"
      },
      "outputs": [],
      "source": [
        "nbins = 100\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "ori_n, ori_bins, _ = ax[0].hist(ori_pots, bins=nbins, facecolor=\"gold\")\n",
        "ax[0].set_title(\"Original\")\n",
        "rec_n, rec_bins, _ = ax[1].hist(rec_pots, bins=nbins, facecolor=\"blue\")\n",
        "ax[1].set_title(\"Reconstruction\")\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    ax[i].set_xlabel(\"Potential\")\n",
        "    ax[i].set_ylabel(\"Counts per bin\")\n",
        "    ax[i].grid(axis=\"y\", alpha=0.1, color=\"black\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gYBkBO5qS6XG",
      "metadata": {
        "id": "gYBkBO5qS6XG"
      },
      "source": [
        "Now we will compare the two distributions by calculating their Jensen–Shannon divergence, a symmetrized version of the Kullback–Leibler divergence, defined as\n",
        "\n",
        "$$\n",
        "    \\operatorname{JSD}(P \\:\\Vert\\: Q) = \\frac{1}{2} D(P \\:\\Vert\\: M)\n",
        "        + \\frac{1}{2} D(Q \\:\\Vert\\: M),\n",
        "$$\n",
        "\n",
        "where $D$ is the usual Kullback–Leibler and $M = (P + Q) / 2$. $P$ and $Q$ must be normalized probability density functions: in our case they will be the bin heights of the previous histograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-hONqfUCDa5x",
      "metadata": {
        "id": "-hONqfUCDa5x"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "\n",
        "def jsd(p, q):\n",
        "    \"\"\"\n",
        "    Returns the Jensen-Shannon divergence of two datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    p = np.asarray(p, dtype=\"float\")\n",
        "    q = np.asarray(q, dtype=\"float\")\n",
        "\n",
        "    # get optimal bin edges (\"fd\" tries to minimize the integral\n",
        "    # of the squared difference between the histogram and\n",
        "    # the theoretical pdf)\n",
        "    rng_pq = (min(np.min(p), np.min(q)), max(np.max(p), np.max(q)))\n",
        "    dxp = np.histogram_bin_edges(p, bins=\"fd\", range=rng_pq)\n",
        "    dxq = np.histogram_bin_edges(q, bins=\"fd\", range=rng_pq)\n",
        "\n",
        "    nb = max(len(dxp), len(dxq))\n",
        "    dx = min(np.diff(dxp)[0], np.diff(dxq)[0])\n",
        "\n",
        "    p, _ = np.histogram(p, bins=nb, range=rng_pq)\n",
        "    q, _ = np.histogram(q, bins=nb, range=rng_pq)\n",
        "\n",
        "    # jensenshannon from scipy normalizes p, q automatically\n",
        "    return jensenshannon(p, q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8949fd7f",
      "metadata": {
        "id": "8949fd7f"
      },
      "outputs": [],
      "source": [
        "jsd(ori_pots, rec_pots)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}