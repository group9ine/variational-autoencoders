{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cb34c7a8",
      "metadata": {
        "id": "cb34c7a8"
      },
      "source": [
        "# Convolutional 2D VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aMHw7UEOnjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aMHw7UEOnjH",
        "outputId": "e82e0954-a19a-4577-a9ec-6cb77a0ec539"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "%cd drive/MyDrive/Colab\\ Notebooks/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2121bf15",
      "metadata": {
        "id": "2121bf15"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f7cdff",
      "metadata": {
        "id": "79f7cdff"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import linalg as la\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.layers import (\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    Input,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Lambda,\n",
        "    Reshape,\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d142e12f",
      "metadata": {
        "id": "d142e12f"
      },
      "source": [
        "## Data Input and Pre-Processing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "728ed42a",
      "metadata": {
        "id": "728ed42a"
      },
      "source": [
        "Define core features of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04bdb140",
      "metadata": {
        "id": "04bdb140"
      },
      "outputs": [],
      "source": [
        "dim = 2\n",
        "numpart = 30\n",
        "latent_dim = 45\n",
        "box_size = 10\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a4ec27dc",
      "metadata": {
        "id": "a4ec27dc"
      },
      "source": [
        "Import and reshape data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xUDU7zChRgh7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUDU7zChRgh7",
        "outputId": "4b82ecb9-af27-4d14-d2e9-5d423836ed1c"
      },
      "outputs": [],
      "source": [
        "dump_dir = \"./dump/\"\n",
        "# read all position files in chosen directory\n",
        "files = glob(dump_dir + \"gamma*_x.txt\")\n",
        "# sort files by gamma value\n",
        "files = np.array(files)[np.argsort([f.split(\"_\")[1] for f in files])]\n",
        "gamma = np.sort([f.split(\"_\")[1] for f in files]).astype(float)\n",
        "\n",
        "# if different from zero, you can pick a single file with a specific gamma\n",
        "choose_one_gamma = 0\n",
        "\n",
        "if choose_one_gamma != 0:\n",
        "    gamma = choose_one_gamma\n",
        "    num_gammas = 1\n",
        "\n",
        "    fname = [f for f in files if f.split(\"_\")[1] == str(gamma)][0]\n",
        "    data = np.loadtxt(fname)\n",
        "    vcs = data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
        "    labels = np.zeros(len(data))\n",
        "else:\n",
        "    num_gammas = files.size\n",
        "    arrays = [np.loadtxt(f) for f in files]\n",
        "\n",
        "    # combine data + reshape, and assign labels to different datasets\n",
        "    data = np.vstack(arrays)\n",
        "    vcs = data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
        "    labels = np.hstack([[i] * len(a) for i, a in enumerate(arrays)])\n",
        "\n",
        "print(\"Original array shape:\", data.shape)\n",
        "print(\"Reshaped array shape:\", vcs.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "77802d2f",
      "metadata": {
        "id": "77802d2f"
      },
      "source": [
        "Sort by distance from origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935ce942",
      "metadata": {
        "id": "935ce942"
      },
      "outputs": [],
      "source": [
        "sort_idx = np.argsort(vcs[:, :, 0] ** 2 + vcs[:, :, 1] ** 2)\n",
        "sorted_vcs = np.array(\n",
        "    [sample[sort_idx[i]] for i, sample in enumerate(vcs)]\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ecc829a1",
      "metadata": {
        "id": "ecc829a1"
      },
      "source": [
        "### Compute distance matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d724534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d724534",
        "outputId": "45ede740-c3ad-44ae-a04a-eacdbdadc296"
      },
      "outputs": [],
      "source": [
        "# metric=\"euclidean\", force=\"no\", checks=True are by default\n",
        "dm = np.array([squareform(pdist(sample)) for sample in sorted_vcs])\n",
        "\n",
        "print(\"Distance matrix shape:\", dm.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dc556d3b",
      "metadata": {
        "id": "dc556d3b"
      },
      "source": [
        "Split in training and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e97d525",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e97d525",
        "outputId": "c04ba75f-6d62-4bc4-81e8-1d25d6fb7974"
      },
      "outputs": [],
      "source": [
        "train_perc = 0.8\n",
        "\n",
        "m = sorted_vcs.shape[0]  # total number of samples\n",
        "m_training = int(m * train_perc)  # samples in the training set\n",
        "m_test = m - m_training  # samples in the test set\n",
        "\n",
        "while True:\n",
        "    permutation = np.random.permutation(m)\n",
        "\n",
        "    sorted_vcs = sorted_vcs[permutation]\n",
        "    labels = labels[permutation]\n",
        "    dm = dm[permutation]\n",
        "\n",
        "    trainset_conf = sorted_vcs[:m_training]\n",
        "    testset_conf = sorted_vcs[m_training:]\n",
        "\n",
        "    trainset_mat = dm[:m_training]\n",
        "    testset_mat = dm[m_training:]\n",
        "\n",
        "    counts = [\n",
        "        np.count_nonzero(labels[:m_training] == i)\n",
        "        for i in range(num_gammas)\n",
        "    ]\n",
        "\n",
        "    # if each label is represented by at least half of\n",
        "    # training set size / number of files\n",
        "    # we're good and we can stop permutating\n",
        "    if all(c > int(m_training / (2 * num_gammas)) for c in counts):\n",
        "        break\n",
        "\n",
        "print(\"Shape of the training set: \", trainset_conf.shape)\n",
        "print(\"Shape of the test set: \", testset_mat.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6ace60bc",
      "metadata": {
        "id": "6ace60bc"
      },
      "source": [
        "## Variational Auto Encoder (Model 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5a611a5b",
      "metadata": {
        "id": "5a611a5b"
      },
      "source": [
        "### Sampling class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f699c38",
      "metadata": {
        "id": "1f699c38"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0e55e13e",
      "metadata": {
        "id": "0e55e13e"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67faee0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67faee0e",
        "outputId": "682d195b-d701-4c24-9e59-5271366b4e40",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.Input(shape=(numpart, numpart, 1))\n",
        "x = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
        "x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "conv_shape = K.int_shape(x)  # Shape of conv to be provided to decoder\n",
        "x = Flatten()(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(\n",
        "    encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\"\n",
        ")\n",
        "encoder.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fcc3e390",
      "metadata": {
        "id": "fcc3e390"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0907c43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0907c43",
        "outputId": "385cc8e9-54f8-4812-bc3a-5061b2d92fe8"
      },
      "outputs": [],
      "source": [
        "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "x = Dense(\n",
        "    conv_shape[1] * conv_shape[2] * conv_shape[3], activation=\"relu\"\n",
        ")(decoder_input)\n",
        "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "x = Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "decoder_outputs = Conv2DTranspose(\n",
        "    1, 3, padding=\"same\", activation=\"sigmoid\", name=\"decoder_output\"\n",
        ")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8a3299e2",
      "metadata": {
        "id": "8a3299e2"
      },
      "source": [
        "### VAE Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5816189c",
      "metadata": {
        "id": "5816189c"
      },
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            # Extract dimensions excluding the first 'None' dimension\n",
        "            size = reconstruction.shape[1:]\n",
        "            # noise = np.random.normal(0, 0.1, size=size)\n",
        "            # reconstruction = reconstruction + noise\n",
        "\n",
        "            # Reshape data to match decoder output shape\n",
        "            data = tf.expand_dims(data, axis=-1)\n",
        "\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                keras.losses.mean_squared_error(data, reconstruction)\n",
        "            )\n",
        "            kl_loss = -0.5 * (\n",
        "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            )\n",
        "            kl_loss = tf.reduce_mean(kl_loss)\n",
        "            total_loss = reconstruction_loss + reg_lambda * kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "77af32ab",
      "metadata": {
        "id": "77af32ab"
      },
      "source": [
        "### Train VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f85776b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f85776b",
        "outputId": "795ba86c-0bbb-4198-c4dd-448cf494c25d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "reg_lambda = 0.001\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        ")  # lower learning rate\n",
        "fit = vae.fit(trainset_mat, epochs=30, batch_size=128, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa509d5",
      "metadata": {
        "id": "4fa509d5"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"font.size\"] = 12\n",
        "fig, AX = plt.subplots(1, 2, figsize=(14, 6.0))\n",
        "ax = AX[0]\n",
        "ax.plot(fit.history[\"loss\"], label=\"MSE loss\", c=\"b\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"MSE loss\")\n",
        "ax.legend()\n",
        "ax = AX[1]\n",
        "ax.plot(fit.history[\"kl_loss\"], label=\"KL loss\", c=\"r\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"KL loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a1e0e846",
      "metadata": {
        "id": "a1e0e846"
      },
      "source": [
        "## Evaluate performance\n",
        "We'll now use the test set to explore the latent space distribution of data and the reconstruction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10df409c",
      "metadata": {
        "id": "10df409c"
      },
      "outputs": [],
      "source": [
        "encoded_test = np.array(vae.encoder.predict(testset_mat))\n",
        "encoded_train = np.array(vae.encoder.predict(trainset_mat))\n",
        "\n",
        "print(encoded_test.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5298c76a",
      "metadata": {
        "id": "5298c76a"
      },
      "source": [
        "We can now use the data to decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40394aeb",
      "metadata": {
        "id": "40394aeb"
      },
      "outputs": [],
      "source": [
        "decoded_test = np.array(decoder.predict(encoded_test[2, :, :])).reshape(\n",
        "    -1, numpart, numpart\n",
        ")\n",
        "decoded_train = np.array(decoder.predict(encoded_train[2, :, :])).reshape(\n",
        "    -1, numpart, numpart\n",
        ")\n",
        "print(decoded_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7602682f",
      "metadata": {
        "id": "7602682f"
      },
      "source": [
        "### Check reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b1aad7",
      "metadata": {
        "id": "43b1aad7"
      },
      "outputs": [],
      "source": [
        "ind = 20\n",
        "df = pd.DataFrame(decoded_test[ind])\n",
        "sns.heatmap(data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f83de44",
      "metadata": {
        "id": "9f83de44"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(testset_mat[ind])\n",
        "sns.heatmap(data=df2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2693cb63",
      "metadata": {
        "id": "2693cb63"
      },
      "source": [
        "## Coordinates Reconstructor (Model 2)\n",
        "The reconstructor is trained on the original distance matrices and predicts the decoded matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbf1ca6",
      "metadata": {
        "id": "5bbf1ca6"
      },
      "outputs": [],
      "source": [
        "rec_inputs = keras.Input(shape=(numpart, numpart, 1))\n",
        "x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(rec_inputs)\n",
        "x = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = Flatten()(x)  # Flatten\n",
        "x = layers.Dense(540, activation=\"relu\")(x)\n",
        "x = layers.Dense(180, activation=\"relu\")(x)\n",
        "x = layers.Dense(numpart * dim)(x)\n",
        "rec_outputs = Reshape((numpart, dim))(x)\n",
        "reconstruction = keras.Model(rec_inputs, rec_outputs)\n",
        "reconstruction.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecef36ae",
      "metadata": {
        "id": "ecef36ae",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "reconstruction.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        ")  # lower learning rate\n",
        "fit = reconstruction.fit(\n",
        "    trainset_mat, trainset_conf, epochs=100, batch_size=128, verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d6ee4",
      "metadata": {
        "id": "fe2d6ee4"
      },
      "outputs": [],
      "source": [
        "rec_test = np.array(reconstruction.predict(testset_mat))\n",
        "rec_test_dec = np.array(reconstruction.predict(decoded_test))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ca075e92",
      "metadata": {
        "id": "ca075e92"
      },
      "source": [
        "### Evaluate performance\n",
        "Original data is in blue, reconstructed original configurations in gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dff11e2",
      "metadata": {
        "id": "6dff11e2"
      },
      "outputs": [],
      "source": [
        "ind = 20\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot()\n",
        "l = np.sqrt(2)\n",
        "ax.scatter(\n",
        "    rec_test[ind, :, 0] * l, rec_test[ind, :, 1] * l, s=30, c=\"gold\"\n",
        ")\n",
        "ax.scatter(\n",
        "    testset_conf[ind, :, 0] * l,\n",
        "    testset_conf[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#023e8a\",\n",
        ")\n",
        "ax.set_xlim(-0.15, 1.15)\n",
        "ax.set_ylim(-0.15, 1.15)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cba87eac",
      "metadata": {
        "id": "cba87eac"
      },
      "source": [
        "Original data is in "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926b8650",
      "metadata": {
        "id": "926b8650"
      },
      "outputs": [],
      "source": [
        "ind = 20\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot()\n",
        "l = np.sqrt(2)\n",
        "ax.scatter(\n",
        "    rec_test_dec[ind, :, 0] * l,\n",
        "    rec_test_dec[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#e63946\",\n",
        ")\n",
        "ax.scatter(\n",
        "    testset_conf[ind, :, 0] * l,\n",
        "    testset_conf[ind, :, 1] * l,\n",
        "    s=30,\n",
        "    c=\"#023e8a\",\n",
        ")\n",
        "ax.set_xlim(-0.15, 1.15)\n",
        "ax.set_ylim(-0.15, 1.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312ed391",
      "metadata": {
        "id": "312ed391",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Create the figure and axis objects\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "nframes = 100\n",
        "\n",
        "\n",
        "# Define the animation function\n",
        "def update(ind):\n",
        "    ax.clear()\n",
        "    plt.scatter(\n",
        "        rec_test[ind, :, 0] * l, rec_test[ind, :, 1] * l, s=20, c=\"b\"\n",
        "    )\n",
        "    plt.scatter(\n",
        "        testset_conf[ind, :, 0] * l,\n",
        "        testset_conf[ind, :, 1] * l,\n",
        "        s=20,\n",
        "        c=\"y\",\n",
        "    )\n",
        "    ax.set_title(f\"Scatter plot ({ind}/{nframes})\")\n",
        "    ax.set_xlim(-0.1, 1.1)\n",
        "    ax.set_ylim(-0.1, 1.1)\n",
        "\n",
        "\n",
        "# Create the animation\n",
        "animation = FuncAnimation(fig, update, frames=nframes, interval=400)\n",
        "\n",
        "# Save the animation as a GIF\n",
        "animation.save(\"conv2dist.gif\", writer=\"imagemagick\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b0642e57",
      "metadata": {
        "id": "b0642e57"
      },
      "source": [
        "## Deez Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0497eb4",
      "metadata": {
        "id": "a0497eb4"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "def label_vis(vae, data, labels):\n",
        "    # prediction\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    transformed_data = pca.fit_transform(z_mean)\n",
        "    variance_ratio = pca.explained_variance_ratio_\n",
        "    print(variance_ratio)\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(transformed_data[:, 0], transformed_data[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36969448",
      "metadata": {
        "id": "36969448"
      },
      "outputs": [],
      "source": [
        "label_vis(vae, dm, labels)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "LGQUmrnEnUJv",
      "metadata": {
        "id": "LGQUmrnEnUJv"
      },
      "source": [
        "## Energy test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf507cc6",
      "metadata": {
        "id": "bf507cc6"
      },
      "outputs": [],
      "source": [
        "def potential(x, gamma):\n",
        "    \"\"\"\n",
        "    Calculate LJ + gravitational potential given a positions array.\n",
        "\n",
        "    INPUTS\n",
        "        x: array of shape (num_particles, dimension)\n",
        "        gamma\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(x)\n",
        "    pot = 0.0\n",
        "    for i in range(n - 1):\n",
        "        pot += gamma * x[i, -1]\n",
        "        for j in range(i + 1, n):\n",
        "            r2 = np.sum((x[i, :] - x[j, :]) ** 2)\n",
        "            if r2 < 9.0:  # r_cut = 3 sigma\n",
        "                sr6 = 1.0 / r2**3\n",
        "                pot += 4 * (sr6**2 - sr6)\n",
        "    pot += gamma * x[-1, -1]\n",
        "\n",
        "    return pot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jCWq5na9_h9E",
      "metadata": {
        "id": "jCWq5na9_h9E"
      },
      "outputs": [],
      "source": [
        "scale_factor = box_size * np.sqrt(dim)\n",
        "ori_pots = [\n",
        "    potential(sample, gamma[labels[idx]])\n",
        "    for idx, sample in enumerate(testset_conf * scale_factor)\n",
        "]\n",
        "rec_pots = [\n",
        "    potential(sample, gamma[labels[idx]])\n",
        "    for idx, sample in enumerate(rec_test_dec * scale_factor)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aBWaQ0iX_qTw",
      "metadata": {
        "id": "aBWaQ0iX_qTw"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "ax[0].hist(ori_pots, bins=30, facecolor=\"gold\")\n",
        "ax[0].set_title(\"Original\")\n",
        "ax[1].hist(rec_pots, bins=30, facecolor=\"blue\")\n",
        "ax[1].set_title(\"Reconstruction\")\n",
        "\n",
        "for i in range(2):\n",
        "    ax[i].set_xlabel(\"Potential\")\n",
        "    ax[i].set_ylabel(\"Counts per bin\")\n",
        "    ax[i].grid(axis=\"y\", alpha=0.1, color=\"black\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
