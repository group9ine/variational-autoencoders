{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb34c7a8",
   "metadata": {
    "id": "cb34c7a8"
   },
   "source": [
    "# Convolutional 2D VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aMHw7UEOnjH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aMHw7UEOnjH",
    "outputId": "2d4f08de-12bf-4bbb-a9e9-4f1b9d643983"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from google.colab import drive\\ndrive.mount(\"/content/drive/\")\\n\\n%cd drive/MyDrive/Colab\\\\ Notebooks/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")\n",
    "\n",
    "%cd drive/MyDrive/Colab\\ Notebooks/'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121bf15",
   "metadata": {
    "id": "2121bf15"
   },
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f7cdff",
   "metadata": {
    "id": "79f7cdff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 12:53:50.604520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import linalg as la\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Input,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    Reshape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142e12f",
   "metadata": {
    "id": "d142e12f"
   },
   "source": [
    "## Data Input and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ed42a",
   "metadata": {
    "id": "728ed42a"
   },
   "source": [
    "Define core features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bdb140",
   "metadata": {
    "id": "04bdb140"
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "numpart = 30\n",
    "latent_dim = 45\n",
    "box_size = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec27dc",
   "metadata": {
    "id": "a4ec27dc"
   },
   "source": [
    "Import and reshape data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "xUDU7zChRgh7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUDU7zChRgh7",
    "outputId": "f2997994-0fcf-4988-8b43-6655a7d188b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array shape: (40000, 60)\n",
      "Reshaped array shape: (40000, 30, 2)\n"
     ]
    }
   ],
   "source": [
    "dump_dir = \"/Users/lorenzobarbiero/Documents/GitHub/variational-autoencoders/mc-sampling/good-runs/\"\n",
    "# read all position files in chosen directory\n",
    "files = glob(dump_dir + \"gamma*_x.txt\")\n",
    "# sort files by gamma value\n",
    "files = np.array(files)[np.argsort([f.split(\"_\")[1] for f in files])]\n",
    "\n",
    "# if different from zero, you can pick a single file with a specific gamma\n",
    "choose_one_gamma = 0\n",
    "\n",
    "if choose_one_gamma != 0:\n",
    "    gamma = choose_one_gamma\n",
    "    num_gammas = 1\n",
    "\n",
    "    fname = [f for f in files if f.split(\"_\")[1] == str(gamma)][0]\n",
    "    data = np.loadtxt(fname)\n",
    "    vcs = data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
    "    labels = np.zeros(len(data))\n",
    "else:\n",
    "    num_gammas = files.size\n",
    "    arrays = [np.loadtxt(f) for f in files]\n",
    "\n",
    "    # combine data + reshape, and assign labels to different datasets\n",
    "    data = np.vstack(arrays)\n",
    "    vcs = data.reshape((-1, numpart, dim)) / (box_size * np.sqrt(dim))\n",
    "    labels = np.hstack([[i] * len(a) for i, a in enumerate(arrays)])\n",
    "\n",
    "print(\"Original array shape:\", data.shape)\n",
    "print(\"Reshaped array shape:\", vcs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77802d2f",
   "metadata": {
    "id": "77802d2f"
   },
   "source": [
    "Sort by distance from origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935ce942",
   "metadata": {
    "id": "935ce942"
   },
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(vcs[:, :, 0] ** 2 + vcs[:, :, 1] ** 2)\n",
    "sorted_vcs = np.array(\n",
    "    [sample[sort_idx[i]] for i, sample in enumerate(vcs)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc829a1",
   "metadata": {
    "id": "ecc829a1"
   },
   "source": [
    "### Compute distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d724534",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d724534",
    "outputId": "d0f58382-c455-4817-c156-99c3a40b4a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (40000, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "# metric=\"euclidean\", force=\"no\", checks=True are by default\n",
    "dm = np.array([squareform(pdist(sample)) for sample in sorted_vcs])\n",
    "\n",
    "print(\"Distance matrix shape:\", dm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc556d3b",
   "metadata": {
    "id": "dc556d3b"
   },
   "source": [
    "Split in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e97d525",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e97d525",
    "outputId": "2c33701b-7504-483a-8f6a-faae0517468d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set:  (32000, 30, 2)\n",
      "Shape of the test set:  (8000, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.8\n",
    "\n",
    "m = sorted_vcs.shape[0]  # total number of samples\n",
    "m_training = int(m * train_perc)  # samples in the training set\n",
    "m_test = m - m_training  # samples in the test set\n",
    "\n",
    "while True:\n",
    "    permutation = np.random.permutation(m)\n",
    "\n",
    "    sorted_vcs = sorted_vcs[permutation]\n",
    "    labels = labels[permutation]\n",
    "    dm = dm[permutation]\n",
    "\n",
    "    trainset_conf = sorted_vcs[:m_training]\n",
    "    testset_conf = sorted_vcs[m_training:]\n",
    "\n",
    "    trainset_mat = dm[:m_training]\n",
    "    testset_mat = dm[m_training:]\n",
    "\n",
    "    counts = [\n",
    "        np.count_nonzero(labels[:m_training] == i)\n",
    "        for i in range(num_gammas)\n",
    "    ]\n",
    "\n",
    "    # if each label is represented by at least half of\n",
    "    # training set size / number of files\n",
    "    # we're good and we can stop permutating\n",
    "    if all(c > int(m_training / (2 * num_gammas)) for c in counts):\n",
    "        break\n",
    "\n",
    "print(\"Shape of the training set: \", trainset_conf.shape)\n",
    "print(\"Shape of the test set: \", testset_mat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace60bc",
   "metadata": {
    "id": "6ace60bc"
   },
   "source": [
    "## Variational Auto Encoder (Model 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a611a5b",
   "metadata": {
    "id": "5a611a5b"
   },
   "source": [
    "### Sampling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f699c38",
   "metadata": {
    "id": "1f699c38"
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55e13e",
   "metadata": {
    "id": "0e55e13e"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67faee0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67faee0e",
    "outputId": "7ea0f67d-6294-444b-e5a6-3c384a14c522",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 30, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 30, 30, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 30, 30, 64)   18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 57600)        0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 45)           2592045     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 45)           2592045     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 45)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,202,906\n",
      "Trainable params: 5,202,906\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 12:53:55.236752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = keras.Input(shape=(numpart, numpart, 1))\n",
    "x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
    "# x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "conv_shape = K.int_shape(x)  # Shape of conv to be provided to decoder\n",
    "x = Flatten()(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(\n",
    "    encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\"\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3e390",
   "metadata": {
    "id": "fcc3e390"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0907c43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0907c43",
    "outputId": "a75ccd36-9570-48a6-a89b-1da847632cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 45)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 57600)             2649600   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 30, 30, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 30, 30, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Conv2DTrans  (None, 30, 30, 1)        289       \n",
      " pose)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,705,281\n",
      "Trainable params: 2,705,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "x = Dense(\n",
    "    conv_shape[1] * conv_shape[2] * conv_shape[3], activation=\"relu\"\n",
    ")(decoder_input)\n",
    "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
    "x = Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "# x = Conv2DTranspose(128, 3, padding='same', activation='relu')(x)\n",
    "x = Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "decoder_outputs = Conv2DTranspose(\n",
    "    1, 3, padding=\"same\", activation=\"sigmoid\", name=\"decoder_output\"\n",
    ")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3299e2",
   "metadata": {
    "id": "8a3299e2"
   },
   "source": [
    "### VAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5816189c",
   "metadata": {
    "id": "5816189c"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            size = reconstruction.shape[\n",
    "                1:\n",
    "            ]  # Extract dimensions excluding the first 'None' dimension\n",
    "            #noise = np.random.normal(0, 0.1, size=size)\n",
    "            #reconstruction = reconstruction + noise\n",
    "\n",
    "            # Reshape data to match decoder output shape\n",
    "            data = tf.expand_dims(data, axis=-1)\n",
    "\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(data, reconstruction)\n",
    "            )\n",
    "            kl_loss = -0.5 * (\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            )\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + reg_lambda * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af32ab",
   "metadata": {
    "id": "77af32ab"
   },
   "source": [
    "### Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85776b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f85776b",
    "outputId": "515e3322-860c-44d5-eb68-048e82e9a830",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 - 122s - loss: 0.0108 - reconstruction_loss: 0.0105 - kl_loss: 0.2925 - 122s/epoch - 489ms/step\n",
      "Epoch 2/10\n",
      "250/250 - 133s - loss: 0.0061 - reconstruction_loss: 0.0053 - kl_loss: 0.7980 - 133s/epoch - 533ms/step\n",
      "Epoch 3/10\n",
      "250/250 - 144s - loss: 0.0050 - reconstruction_loss: 0.0040 - kl_loss: 0.9643 - 144s/epoch - 575ms/step\n",
      "Epoch 4/10\n",
      "250/250 - 146s - loss: 0.0044 - reconstruction_loss: 0.0032 - kl_loss: 1.1332 - 146s/epoch - 585ms/step\n",
      "Epoch 5/10\n",
      "250/250 - 154s - loss: 0.0039 - reconstruction_loss: 0.0026 - kl_loss: 1.2510 - 154s/epoch - 615ms/step\n",
      "Epoch 6/10\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.001\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")  # lower learning rate\n",
    "fit = vae.fit(trainset_mat, epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa509d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "4fa509d5",
    "outputId": "b438b06f-8563-4c33-c3a7-2a773ba9693b"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "fig, AX = plt.subplots(1, 2, figsize=(14, 6.0))\n",
    "ax = AX[0]\n",
    "ax.plot(fit.history[\"loss\"], label=\"MSE loss\", c=\"b\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"MSE loss\")\n",
    "ax.legend()\n",
    "ax = AX[1]\n",
    "ax.plot(fit.history[\"kl_loss\"], label=\"KL loss\", c=\"r\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"KL loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0e846",
   "metadata": {
    "id": "a1e0e846"
   },
   "source": [
    "## Evaluate performance\n",
    "We'll now use the test set to explore the latent space distribution of data and the reconstruction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df409c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10df409c",
    "outputId": "c58ab730-b8b6-4a4f-88ae-25a80293ea7d"
   },
   "outputs": [],
   "source": [
    "encoded_test = np.array(vae.encoder.predict(testset_mat))\n",
    "encoded_train = np.array(vae.encoder.predict(trainset_mat))\n",
    "\n",
    "print(encoded_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298c76a",
   "metadata": {
    "id": "5298c76a"
   },
   "source": [
    "We can now use the data to decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40394aeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40394aeb",
    "outputId": "c4f2ca99-1260-4bd5-beb9-4b00094dc0a8"
   },
   "outputs": [],
   "source": [
    "decoded_test = np.array(decoder.predict(encoded_test[2, :, :])).reshape(\n",
    "    -1, numpart, numpart\n",
    ")\n",
    "decoded_train = np.array(decoder.predict(encoded_train[2, :, :])).reshape(\n",
    "    -1, numpart, numpart\n",
    ")\n",
    "print(decoded_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602682f",
   "metadata": {
    "id": "7602682f"
   },
   "source": [
    "### Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1aad7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "43b1aad7",
    "outputId": "a38bcb47-eb83-4f54-81fc-bc0c364fa673"
   },
   "outputs": [],
   "source": [
    "ind = 20\n",
    "df = pd.DataFrame(decoded_test[ind])\n",
    "sns.heatmap(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83de44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "9f83de44",
    "outputId": "11527a40-720f-4241-a144-500ea77e37f0"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(testset_mat[ind])\n",
    "sns.heatmap(data=df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d50d4",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(encoder, \"./models/enc\")\n",
    "tf.keras.models.save_model(decoder, \"./models/dec\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
