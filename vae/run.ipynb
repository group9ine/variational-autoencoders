{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fc6d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 11:03:26.622223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 11:03:28.234940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 11:03:28.235063: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 11:03:28.235078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-22 11:03:30.349775: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-22 11:03:30.349818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (davide-PC): /proc/driver/nvidia/version does not exist\n",
      "2023-05-22 11:03:30.350732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from spatial_scan import scan, deploy\n",
    "from vae import VAE, encoder, decoder, tf, keras,l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca1fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_len = 1000\n",
    "lmax=0.1\n",
    "\n",
    "with open(\"../mc-sampling/good-runs/test_30_5_0.05_0.3_0.1_10000_1000_1000_x.txt\") as f:\n",
    "    data = [[float(i.strip()) for i in s.split(\" \") if i!=\"\"] for s in f.read().split(\"\\n\") if s!=\"\"]\n",
    "    xyz=[[[data[h][i+3*j]for i in range(3)]for j in range(len(data[h])//3)]for h in range(len(data))]\n",
    "    del data\n",
    "\n",
    "# print(len(data), [len(data[i]) for i in range(len(data))])\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\"./checkpoints/\", save_best_only=True)\n",
    "\n",
    "def change_l(e,log):\n",
    "    global l, lmax\n",
    "    print(\"l: \", l)\n",
    "    l=(1-1/(1+e))*lmax\n",
    "\n",
    "regularization_callback = keras.callbacks.LambdaCallback(on_epoch_begin=change_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486cee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:#len(argv)>2 and argv[2]==\"--resume\":\n",
    "    encoder=keras.models.load_model(\"./model-info/enc\")\n",
    "    decoder=keras.models.load_model(\"./model-info/dec\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bed5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Epoch 1/2\n",
      " 286/1000 [=======>......................] - ETA: 2:02 - loss: 0.0300 - reconstruction_loss: 0.0300 - kl_loss: 1.1232"
     ]
    }
   ],
   "source": [
    "for i in range(1):#(ceil(len(xyz)/batch_len)):\n",
    "    bdata = [] # will hold bucketed data version\n",
    "    for j in range(batch_len*i, batch_len*(i+1)):\n",
    "        if j>len(xyz):\n",
    "            break\n",
    "        #print(xyz[j])\n",
    "        bdata.append([scan(xyz[j],5,5,5)])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((bdata,))\n",
    "    print(\"i: \",i)\n",
    "    vae.fit(dataset, epochs=2, batch_size=128, callbacks=[model_checkpoint_callback, regularization_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f3c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    vae.load_weights(\"./checkpoints/\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    keras.models.save_model(vae.encoder, \"./model-info/enc/\")\n",
    "    keras.models.save_model(vae.decoder, \"./model-info/dec/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28103aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(ncols=3)\n",
    "ax[0].plot(vae.history.history[\"loss\"])\n",
    "ax[1].plot(vae.history.history[\"reconstruction_loss\"])\n",
    "ax[2].plot(vae.history.history[\"kl_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130db5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=[]\n",
    "for j in range(batch_len, batch_len*2):\n",
    "    if j>len(xyz):\n",
    "        break\n",
    "    test_set.append([scan(xyz[j],5,5,5)])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_set,))\n",
    "\n",
    "pred = vae.encoder.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe27bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.scatter(x=[p[0] for p in pred[2]], y=[p[1] for p in pred[2]])\n",
    "#print(len([p[0] for p in pred[2]]), len([p[1] for p in pred[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809493af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata=np.random.normal(0,1, size=(30,2))\n",
    "pred=decoder.predict(rdata)\n",
    "x,y,z=deploy(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x,y,z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
