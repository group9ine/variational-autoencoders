{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fc6d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 11:14:08.033106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 11:14:09.535485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-31 11:14:09.535612: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-31 11:14:09.535627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-31 11:14:11.679456: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-31 11:14:11.679501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (davide-PC): /proc/driver/nvidia/version does not exist\n",
      "2023-05-31 11:14:11.679864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from spatial_scan import scan, deploy, rand_deploy\n",
    "from vae2d import VAE, encoder, decoder, tf, keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2a6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 100\n",
    "half=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca1fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_len = 1000\n",
    "lmax=0.5\n",
    "half=False\n",
    "\n",
    "with open(\"../overfittabile_x.txt\") as f:\n",
    "    data = [[float(i.strip()) for i in s.split(\" \") if i!=\"\"] for s in f.read().split(\"\\n\") if s!=\"\"]\n",
    "    xyz=[[[data[h][i+2*j]for i in range(2)]for j in range(len(data[h])//2)]for h in range(len(data))]\n",
    "    #print(len(data[0]), len(xyz[0]), len(xyz[0][0]))\n",
    "    del data\n",
    "\n",
    "# print(len(data), [len(data[i]) for i in range(len(data))])\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\"./checkpoints2d/\", save_best_only=True)\n",
    "# currently unused\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486cee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "if True:#len(argv)>2 and argv[2]==\"--resume\":\n",
    "    encoder=keras.models.load_model(\"./modified-model-info2d/enc\")\n",
    "    decoder=keras.models.load_model(\"./modified-model-info2d/dec\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "losses=[]\n",
    "rec_losses=[]\n",
    "kl_losses=[]\n",
    "l_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ef7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, mymodel):\n",
    "        super().__init__()\n",
    "        self.mymodel=mymodel\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        global lmax, half\n",
    "        self.mymodel.l.assign( (1-1/(1+epoch/10))*lmax )\n",
    "        lmax+=0.0005\n",
    "        if not half:\n",
    "            self.mymodel.r.assign( 1/(1+epoch/10) )\n",
    "        else:\n",
    "            self.mymodel.r.assign( 0 )\n",
    "        #print(\"l: \", self.mymodel.l)\n",
    "\n",
    "regularization_callback = CustomCallback(vae)\n",
    "\n",
    "old=\"\"\"            \n",
    "def change_l(e,log):\n",
    "    global lmax, half\n",
    "    vae.l = (1-1/(1+e/10))*lmax\n",
    "    lmax+=0.0005\n",
    "    if not half:\n",
    "        vae.r = 1/(1+e/10)\n",
    "    else:\n",
    "        vae.r = 0\n",
    "    #print(\"l: \", vae.l)\n",
    "\n",
    "regularization_callback = keras.callbacks.LambdaCallback(on_epoch_begin=change_l)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790e0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655c4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bed5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- i:  0\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.0>\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.0455>\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.0835>\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.11573077>\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.14342856>\n",
      "l:  <tf.Variable 'l:0' shape=() dtype=float32, numpy=0.1675>\n"
     ]
    }
   ],
   "source": [
    "for i in range(ceil(len(xyz)/batch_len)):\n",
    "    bdata = [] # will hold bucketed data version\n",
    "    for j in range(batch_len*i, batch_len*(i+1)):\n",
    "        if j>len(xyz):\n",
    "            break\n",
    "        #print(xyz[j])\n",
    "        bdata.append([scan(xyz[j],8,8, dim=2)])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((bdata,))\n",
    "    print(\" ----- i: \",i)\n",
    "    if i>ceil(len(xyz)/batch_len)//2:\n",
    "        half=True\n",
    "    \n",
    "    vae.fit(dataset, epochs=nepochs, batch_size=128, callbacks=[regularization_callback], verbose=0)\n",
    "    losses.extend(vae.history.history[\"loss\"])\n",
    "    rec_losses.extend(vae.history.history[\"reconstruction_loss\"])\n",
    "    kl_losses.extend(vae.history.history[\"kl_loss\"])\n",
    "    l_values.extend(vae.history.history[\"l\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6d5a4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "try:\n",
    "    vae.load_weights(\"./checkpoints2d/\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    keras.models.save_model(vae.encoder, \"./modified-model-info2d/enc/\")\n",
    "    keras.models.save_model(vae.decoder, \"./modified-model-info2d/dec/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda301bf",
   "metadata": {},
   "source": [
    "vae.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28103aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(ncols=4)\n",
    "ax[0].plot(losses)#vae.history.history[\"loss\"])\n",
    "ax[1].plot(rec_losses)#vae.history.history[\"reconstruction_loss\"])\n",
    "ax[2].plot(kl_losses)#vae.history.history[\"kl_loss\"])\n",
    "ax[3].plot(l_values)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f137a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130db5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=[]\n",
    "for j in range(batch_len, batch_len*2):\n",
    "    if j>len(xyz):\n",
    "        break\n",
    "    test_set.append([scan(xyz[j],8,8, dim=2)])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_set,))\n",
    "\n",
    "pred = vae.encoder.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe27bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(ncols=5, nrows=5)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i!=j:\n",
    "            ax[i][j].scatter(x=[p[i] for p in pred[2]], y=[p[j] for p in pred[2]], s=5)\n",
    "        else:\n",
    "            ax[i][i].hist(x=[p[i] for p in pred[2]])\n",
    "fig.tight_layout()\n",
    "#print(len([p[0] for p in pred[2]]), len([p[1] for p in pred[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c05fb",
   "metadata": {},
   "source": [
    "ndata=2000\n",
    "N=25\n",
    "rdata=np.random.normal(0,2, size=(ndata,5))\n",
    "rec=decoder.predict(rdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = decoder.predict(pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809493af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[None for i in range(len(rec))]\n",
    "y=[None for i in range(len(rec))]\n",
    "for i in range(len(rec)):\n",
    "    print(i, end=\"\\t\", flush=True)\n",
    "    x[i],y[i]=rand_deploy(rec[i], dim=2, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print([(len(x[i]),len(y[i])) for i in range(ndata)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23affc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd76d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "fig, ax=plt.subplots(ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rec)):\n",
    "    ax[1].scatter(np.random.normal(0,0.1, size=(N,))+y[i],np.random.normal(0,0.1, size=(N,))+x[i], marker=\".\", s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"xplot=[]\n",
    "yplot=[]\n",
    "cols=[]\n",
    "for i in range(len(rec[0])): #80\n",
    "    xplot.append([])\n",
    "    yplot.append([])\n",
    "    cols.append([])\n",
    "    for j in range(len(rec[0][i])): #80\n",
    "        xplot[i].append(j/8)\n",
    "        yplot[i].append(i/8)\n",
    "        cols[i].append(0)\n",
    "        for k in range(len(rec)):\n",
    "            cols[i][j] += rec[k][i][j]\n",
    "        #cols[i][j] *= 30\n",
    "\n",
    "xplot=np.array(xplot).flatten()\n",
    "yplot=np.array(yplot).flatten()\n",
    "cols=np.array(cols).flatten()\n",
    "rgb = mpl.colormaps[\"coolwarm\"](cols)\n",
    "\n",
    "ax[1].scatter(yplot, xplot, s=1, c=rgb)\n",
    "\"\"\"\n",
    "for j in range(len(rec)):\n",
    "    ax[0].scatter([i[0] for i in xyz[j]],[i[1] for i in xyz[j]] , color=\"red\", marker=\".\", s=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
